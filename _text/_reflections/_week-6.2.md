## Raphi
For Thursday 3/7:
I noticed a similar thread of historical connection in the Smits and Wevers reading as I saw in the Tuesday Underwood reading. As I wrote in an annotation, I was immediately reminded of the “Datasitters Club” article as well as Pippa’s presentation on the Graphic Novel Corpus. While there is also a history of scholars interacting with images using technology and taking data from those images, the authors noted that this has been much more common with text. These authors also seemed very intent on grounding their study on technology in history, and I wonder if that is due to a desire to sound credible.

To me, the most valuable aspect of the Smith and Wevers reading was the specific case studies the authors provided. In particular, I thought that the study on the role of families in children’s literature helped me conceptualize the potential of digital humanities to make meaningful contributions to the field. While it had long been accepted that children’s literature centered around the relationship between child and family, digital humanities allowed scholars to challenge that theory and situate it in a much broader context. In general, this ability might allow scholars to either further or challenge and raise issues with our pre-existing conclusions and notions.

I also really appreciated the historical and modern day context highlighted in Nguyen’s, “How we do things with Words.” The questions Nguyen is attempting to answer about the prevalence and role of hate speech helped expand my understanding of insight-driven computational analysis because the questions themselves are quite insightful, pressing questions in modern day society. Thus, knowing that data can help us answer these questions, while recognizing that it cannot give us all of the answers and accounting for potential holes as well as loss of information via data cleaning, helps me contextualize the importance of data in my own life. The questions are very humanistic, even if the methods toward answering them might not typically be conceived as such.

Overall, I thought that these texts reinforced some of the ideas we’ve encountered in previous readings about how texts and artifacts must be taken within the context in which they are culturally situated. There are human beings involved in the process of taking these documents, and not just transcribing/uploading them, but also computationally analyzing them. Thus, there will always be multiple layers of bias and potential historical injustices with which to contend in the field, posing significant challenges. However, accounting for these challenges in advance and being honest about one’s own role as a researcher and data analyst makes the process a lot more humanistic in my opinion, which I think is very valuable in data-driven contexts.


## Pia Bhatia
  1:25 PM
The piece on multimodality in approaches to digital humanities projects gave me a lot of insight into how computers’ “brains” work. It may seem obvious, but I think I needed to see how literal interpretations can be: ‘families’ included those of animals, photographs of young girls caring for either younger siblings or dolls (these were placed in a single category), etc. I am curious about how these softwares break down elements of a photograph, and what computer categorizations look like. Again, this is obvious, but it’s both similar and dissimilar to how we interact with photographs—we recognize elements in them from our past experiences (‘inputs’), for example. Though multimodal, the models are still confined to images and text, and don’t address some of the wider questions being asked about less mainstream media. This process of labeling does feel reductive as well, and makes all succeeding research hinge on the first authors’ attempts which seems precarious. I would love to read more about the historical origins of the visual biases that cloud the results we do currently have, and what is being done to address them.


## Anya Kalogerakos
  2:01 PM
I think the Nguyen reading has been my favorite digital humanities research walk through that we have read. I found it to be very clear, informative, and it stepped through the challenges of each of the aspects of digital research very well. One distinction I found particularly helpful was the distinction between using supervised and unsupervised learning. The description of both has made me realize that I do not understand unsupervised learning as well as I thought and I have many questions as to how it can be used faithfully in humanities research if we do not always know why it is making the decisions it is making. That being said, it clearly produces efficient and effective results. The Smits and Wevers reading was also an interesting read as it is one of the few readings we have had so far that has discussed the use of visual collections in research. This reading did a great job of reminding me how much material is outside of the scope of textual analysis. I am very interested to see where the concept of “multimodal materials” and their analysis goes as our computer models grow more capable of understanding complex materials. I think this could be a very important evolution in the digital humanities that is able to incorporate some of the physical/visual attributes of a text into mutable data.


## Clay Glovier
  3:40 PM
I enjoyed reading both the Nguyen and Smit articles. In Smit’s paper, it was interesting to learn about how visual sources are becoming increasingly important in the modern world. I hadn’t really thought about how many more images are prevalent in our lives through the advent of photography and social media. In the middle ages readers only really had access to paintings and drawings, which offer significantly less information and were much less accessible to readers than modern images that can both capture the reality of the world with high accuracy while also having the ability to misrepresent the world. It was also interesting to read how we have developed sophisticated computer systems to analyze the billions of images that we have, but that our models to analyze textual sources are farther behind. On one hand it seems easier to analyze images than text, but perhaps this is because I have used more image-editing softwares than text-editing programs. In the Nguyen article, it was interesting to learn about the connections between topics and metadata elements. Tags such as “hate speech” imply a certain way of organizing data, yet how can one really determine what hate speech is? There are many different definitions and forms, and to some certain actions may not be considered hate speech while to others they are. It will be very important as these models are further developed to ensure that nuance is kept in mind, that biases are recorded, and that the practice of researchers categorizing general terms in different, obscured ways is avoided. (edited) 


## Alison Fortenberry
  4:30 PM
The Nguyen et al. article really did a good job of breaking down some of the difficulties, but also a lot of the benefits of interdisciplinary approaches to research, namely, insight-driven computational analysis. This approach seems to bring together the best of both worlds– computational analysis is contextualized by non-computational  trends, and the time-consuming process of traditional insight-driven research is greatly reduced. I really appreciated the insights provided about each stage of the research process, as originally I kind of conceptualized this process as just explicitly informing methodology, and thought that everything else would flow naturally from that. Breaking the process down this way showed how much intentionality has to go into each phase of the research process. The Smits reading was also really interesting, especially when they turned around the idea that images need text to be understood to argue that we need to connect images to text in order to understand it. I wonder if multimodal models may be more prone to adopting human bias than just text models or just image models. While text and image models can be taught bias (e.g. stigmatizing certain words/ connecting certain negative phrases with certain people groups, categorizing images into biased categories based on training input), I wonder if the presence of both text and image strengthens these biases, as taught textual bias could be paired with taught visual bias, possibly creating a more informed or comprehensive learned bias. Is there a way to train models like these using human inputs, no matter how intentionally anti-biased, to have no bias, or is bias inherent to human expressions used to train models?


## Pippa LaMacchia
  9:11 PM
I was particularly struck by the Nguyen et al. article “How We Do Things With Words: Analyzing Text as Social and Cultural Data” because it feels like a very grounded approach to the interdisciplinary future of digitization. As a humanities student, I often feel threatened by the increasing accessibility and dependency on computational tools but this article emphasized that the future of digital humanities must rely on a diversity of thought. At the end of the article the field is described as “insight driven computational analysis of text…,” perfectly describing this upcoming research method and field. It is an in-between approach that takes advantage of bias and subjectivity instead of pretending it doesn’t exist. The Smits article was also enlightening because it discusses bias in the more specific context of image/text analysis. I hadn’t before considered how bias appears in computational approaches like this because I often function on the assumption that digital tools are objective (but if I’ve learned anything in this course it’s that this is certainly not true). I am interested in discussing the overlap between these two articles and subjectivity versus objectivity in the digital fields.


## Talia Goldman
  10:58 PM
I especially enjoyed the Smits and Wevers reading–an an art history major, I appreciate the emphasis they place on the relationship between image and text. I thought, for example, about how DH tools could be used to illuminate trends regarding text and image in illuminated manuscripts, which often include illuminated letters that connect to themes of the text. Looking at the interplay between image and text encompasses so much humanities material–our postcards, newspapers, illustrations in books (not just children’s), artworks, posters, etc–that this type of research is really necessary to engage with the humanities and opens many doors for using DH in new ways. In the Nguyen et. al text, I thought the example of what newspapers get digitized (in the section about data quality) was an interesting perspective on how questions framed in the Nguyen et. al article, such as questions of authorship and representativeness of a dataset, relate to the questions of bias framed in the "family" example in Smits and Wevers article. Bias in DH tools seems apparent in most tools and approaches, but the awareness of it in both articles (and previous readings) is an important start to address the complicated issue--and perhaps, our use of DH approaches actually helps humanists as a whole understand their biases more fully than ever before. Overall, I found that these two articles drew together ideas of text recognition, markup, and distant reading that we’ve been discussing, but extended these ideas to a greater extent to visual media, including social media, while further proposing ways to ensure that DH are conducting fair and quality “experiments” on cultural data.


## Andrew Huo
  1:22 PM
Nguyen’s article, “How We Do Things With Words: Analyzing Text as Social Cultural Data” was interesting to me as it brought to my attention this conflict between computational approaches and cultural and social context. Success in current computational tasks are measured by how accurate their predictions are instead of the “relationships between theoretically-motivated constructs from the social sciences and humanities” (Nguyen, 2). Throughout our readings the theme of contradiction between cultural and social context and computational methods and limitations is becoming more and more apparent. For example, a page later, Nguyen discusses the definition of concepts, but how can definitions in humanities (that exist through context, change, and comparison) become standardized in machine learning. And if not then there will be many discrepancies when comparing research data and building off of previous work. Nguyen states, “the notion of ground truth is uncommon in the humanities and social sciences and it is often taken too far in machine learning” (Nguyen, 3). How can there be a standardized consistency then that is necessary for computational analysis?

Smits article, “A multimodal turn in Digital Humanities. Using contrastive machine learning models to explore, enrich, and analyze digital historical collections” felt like an answer and a step in the right direction for the many questions that I had concerning digital humanities. Analyzing images through other images and texts provides meaning multiplication that I agree “is not the same if we would see the text and image independently from each other.” This is one of the ways in which the use of technology can elevate the social and cultural contexts for images, texts, etc… and cross reference them.


## Layla Williams
  8:23 PM
This week’s readings have been the most clear to me in terms of the biases and uses of some of the methods within the digital humanities. I know a couple of people have already talked about the instance of the family example, but I think it was really helpful to see how a single term might not be as direct as it might initially appear. When was the concept of what a family might look like taken from? Is it our understanding from the 18th century or from the 1950s which might be our typical understanding of the nuclear family? Or is it a more modern definition which is more open to the possibilities of the diversity of gender and race within a family? However, what kind of information or photos would the researcher have to feed to the software in order for them to expand this kind of knowledge? Would this have to go deeper into the actual relationships and emotions of subjects in the image? For example, would the software have to look for love within the image? But then how would a software define love when we do not even have a solid definition of it ourselves? What in an expression would give this away? And how might this exclude unhappy families? The deeper I get into this swirl of questions I wonder about for what subject this method would be the most effective. Maybe it is helpful for sorting paintings in a museum, but it might not be as helpful for actually doing the analysis of the compositions.


## Melissa Woo
  11:12 PM
In reading Nguyen et al.'s exploration of text as a medium for understanding social and cultural dynamics, I was struck by the depth of insight that can be garnered from analyzing how we use words. The idea that text is not just a passive repository of information but an active participant in cultural and social expression resonates deeply with me. It reminds me that every word choice, every phrase, carries weight and reflects broader societal patterns and individual intentions. I'm particularly intrigued by the challenge of accounting for nuances like sarcasm or cultural context in computational analyses. It raises important questions for me about the limits and capabilities of AI in capturing the full spectrum of human expression and the critical role of human oversight in interpreting these data.
Smits and Wevers' discussion on the multimodal turn in digital humanities is an interesting perspective on how we can analyze cultural artifacts. The incorporation of visual and possibly even auditory data alongside text suggests a more holistic approach to understanding human culture and history. The potential to uncover new insights by cross-referencing different data modalities is exciting, yet it also introduces a layer of complexity in ensuring the accuracy and meaningfulness of these analyses. I find myself considering the implications of these methodologies for future research, particularly how they can foster interdisciplinary collaborations and push the boundaries of traditional humanities research.


## James Sowerby
  12:16 AM
I thought Smit and Wever's article was deeply fascinating and introduced a topic I had not thought at any length about before. The idea that there are image-text connections that are necessary or illuminating for research makes a lot of sense to me, although I don't often do much visual analysis in my day to day life. But the thought that a model could help to parse the differences and start to provide a framework from which these can be used as research tools is honestly really impressive. It so happens for someone like me, who has very little experience in this field, to be impressed—but this really seems extremely cool. This has a lot of ethical dimensions to it, which others have brought up, but one part about this that I noticed was just the length to which Smit/Wevers cited their images. All the figures seemed to have links to blog posts, and most of the images had meticulous references to other articles as sources, along with the users who uploaded them. It seemed a small but really relevant way to demonstrate the dynamic between metadata, ethics, accessibility, and large modeling, even as you are explaining these topics. The Nguyen article was also a great explanation of some of the pitfalls of data analysis, and I really liked the part about data preprocessing simply to see what the pitfalls of this process is. The idea that tokenization can run into problems like unifying lemmas, creative orthography, or multiword phrases drove the point home to be how important the human touch still is in all of this automation. There still seems to be some humanism at play here


## Emanuelle Sippy
  12:39 AM
The authors of “How We Do Things With Words: Analyzing Text as Social and Cultural Data” make a compelling case that “model outputs” and “close reading” are both necessary and enrich scholarship. Quoting Piper (2015, p. 67-68), who writes that together the approaches “further discovery in two directions,” the authors suggest that outputs shed light on the content of the text and close reading in conversation with the outputs is like a check and balance on the models themselves (Dong, et al. 10). In the realm of multimodal innovation in Digital Humanities, Smits, Thomas, and Wevers draw on theorists such as Sontag and Foucault among others, to argue that text and image are mutually constitutive. Moreover, with the proliferation of visual culture, they assert that DH needs to adapt and become multimodal. Some of the examples of multimodal DH projects that they recount, particularly when looking at images of families and gendered care-taking roles, raise interesting questions about how it is vital for tools like CLIP to recognize stereotypes since they have shaped lived experiences but also equally important that these tools do not further discrimination or reify stereotypes. I am interested to learn more about how these tools can both accurately portray the realities of stereotypes and discrimination in our society without misrepresenting or failing to recognize where change has occurred, such as in conceptions of what constitutes a family or who performs care-work.


## Colin Brown -- late
  2:01 PM
From this week’s readings, what stood out to me the most was that the Smits and Wevers paper was basically advocating for the application of an OpenAI product for usage in digital humanities. When I started reading the paper, my thinking was they the authors had developed a model like CLIP, but when I realized that the model had actually been an OpenAI project, it made me think about the vast discussions going on right now about the use of ChatGPT (obviously another OpenAI development) in educational and research settings. Many people wonder, of course, about how much ChatGPT should be allowed for, say, writing papers, answering homework questions, and performing data analysis. As such, I can imagine the use of CLIP within DH will draw similar questions regarding humans producing original work.

Smits and Wever also take note to discuss the biases that are inherently present in multimodal models like CLIP, so these of course would shape research that uses these tools. At the same time, we also had an extensive discussion during our last class about how humanities research is often always subjective. Ngyuen et al. even goes on to say that literary work and social sciences rarely have ground truths in those fields of work. Therefore, this drawback of CLIP may just be part of an inherent discussion that is always needed anyway for DH research. Regardless of the drawbacks, I agree with Smits and Wever that multimodal models enable an extremely enticing field of research that will open up new possibilities within DH.


## Yaashree Himatsingka -- late
  12:53 AM
Both articles advocate for embracing plural methods in digital humanities research – while Nguyen emphasizes the complexity of textual data and the need to place it in sociocultural context, Smits and Wevers argue for multimodal approaches that, in their paper, homes in on the untapped potential of visual historical collections. I agree with Smits and Wever that methods encompassing both textual and visual elements would lead to a broader, more inclusive understanding of historical data and artifacts. I also agree with Nguyen’s call for a nuanced approach to textual analysis which recognizes performative aspect. However, both articles implicitly indicate the challenges of integrating these diverse analytical techniques into computational methods. For instance, the integration of textual and visual analysis, as Smits and Wevers advocate, raises questions about the scalability and technological challenges in creating systems that can understand the nuanced differences between text and image, or even within varied textual formats themselves. Thus, while these articles make clear that the future of digital humanities lies in its ability to incorporate new technologies and a wide range of disciplinary lenses, they also highlight how challenging it may be to do so.